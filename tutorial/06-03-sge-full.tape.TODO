# Chapter 6: Submitters
# Lesson 3:  Sun Grid Engine (Full Planned Version)

task hello :: .submitter=sge .walltime="00:01:00" .vmem=1g .q=all.q {
  echo hello
}

# * The resource parameter vmem can be specified as .vmem at task declarations
# * The "cmds" parameter is inserted as a direct string replacement by ducttape
#   and contains the "payload" of this task
# * This assumes that scheduler submission happens asynchronously
#   and that we must poll the scheduler to learn when the job has completed
submitter sge :: vmem walltime q /* these can be passed as parameters to each task: .cpus .vmem .walltime .q */
              :: COMMANDS /* the bash commands from some task */
              :: TASK REALIZATON CONFIGURATION /* variables passed by ducttape */ {
  action run > jobid {
    wrapper="job.sh"
    echo "#$ -S /bin/bash" >> $wrapper
    echo "#$ -q $q" >> $wrapper
    echo "#$ -l h_rt=$walltime" >> $wrapper
    echo "#$ -j y" >> $wrapper
    echo "#$ -o localhost:$PWD/job.out" >> $wrapper
    echo "#$ -N $CONFIGURATION-$TASK-$REALIZATION" >> $wrapper

    # Bash flags aren't necessarily passed into the scheduler
    # so we must re-initialize them
    echo "set -e # stop on errors" >> $wrapper
    echo "set -o pipefail # stop on pipeline errors" >> $wrapper
    echo "set -u # stop on undeclared variables" >> $wrapper
    echo "set -x # show each command as it is executed" >> $wrapper

    # The current working directory will also be changed by most schedulers
    echo "cd $PWD" >> $wrapper

    echo "$COMMANDS" >> $wrapper

    qsub $wrapper > $jobid
  }

  action get_queue > q {
    qstat -u jhclark > $q
  }

  # Can ducttape check exit code before doing this? Or is that bad for the FS?
  action check_job < jobid q > done exit_code {
    # If job not in q, it's done
    line=$(fgrep $jobid $q) 
    # But was it successful? Can we always wrap a child JVM to take care of this?
    
  }

  # Ducttape will run this once every n seconds
  # TODO: Is there any way to get around this silly jobid file?
  # TODO: Can we have one function for grabbing the qsub output globally and another for just this job?
  action poll < jobid > done exit_code {
   # Note: This is complicated by having to poll rather than being able to just use SGE's -sync
   # It also allows ducttape to "resume" jobs submitted to the scheduler if a gateway node goes down

   jobid=$(cat $jobid | cut -d. -f1) # Remove server name, if specified
   [[ "$jobid" != "" ]] || (echo >&2 "ERROR: Empty job id. Did the job fail to submit?"; exit 1)

   # Use -alm to avoid costly queries to logs we don't even need
   exit_status=$(tracejob -alm $jobid | awk '/Exit_status=-?[0-9]+/{print $4}' | cut -d= -f2)
   if [[ "$exit_status" != "" ]]; then
     echo >&2 "Job exited with status $exit_status" # Ducttape has stdout/stderr
     exit $exit_status
   fi
  }

  action status > short_status long_status {
    qstat -f $id | awk '/job_state = Q/{print "queued"} /job_state = R/{print "running"}' > $status
  }
}

# NOTE: File transfers and decompression are handled by
# a per-machine limit for each of these tasks and are
# but are not included in the submit-script time
